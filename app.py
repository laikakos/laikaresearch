from utils.text_processor import (
    extract_text_from_docx,
    extract_text_from_pdf,  # â† EKLE
    split_into_sentences,
    find_keyword_contexts,
    clean_text
)

from utils.models import analyze_text_with_all_models
from utils.visualizer import (
    create_emotion_radar_chart,
    create_results_dataframe
)

# Sayfa ayarlarÄ±
st.set_page_config(
    page_title="Qatar Sentiment Analysis",
    page_icon="ğŸ†",
    layout="wide"
)

# BaÅŸlÄ±k
st.title("ğŸ† Qatar DÃ¼nya KupasÄ± Duygu Analizi")
st.markdown("### Almanca Haber Metinleri iÃ§in Ã‡oklu Model KarÅŸÄ±laÅŸtÄ±rmasÄ±")

st.markdown("""
Bu uygulama 3 farklÄ± model ile Almanca metinlerde duygu analizi yapar:
- **Model 1:** HÄ±zlÄ± Pilot (Guhr et al. LREC 2020)
- **Model 2:** Haber Metinleri (mdraw - Ã¶zelleÅŸtirilmiÅŸ)
- **Model 3:** DetaylÄ± Akademik (GoEmotions - 27 duygu)
""")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    
    # Anahtar kelimeler
    st.subheader("Anahtar Kelimeler")
    keywords_input = st.text_area(
        "Her satÄ±ra bir kelime",
        value="Qatar\nKatar\nWeltmeisterschaft\nFuÃŸball\nWM",
        height=150
    )
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
    
    # Context window
    st.subheader("Context Window")
    context_before = st.slider("Ã–nceki cÃ¼mle sayÄ±sÄ±", 0, 5, 3)
    context_after = st.slider("Sonraki cÃ¼mle sayÄ±sÄ±", 0, 5, 3)
    
    st.markdown("---")
    st.markdown("**GeliÅŸtirici:** laikaresearch")

# Ana iÃ§erik
tab1, tab2, tab3 = st.tabs(["ğŸ“„ Dosya YÃ¼kle", "ğŸ“Š SonuÃ§lar", "â„¹ï¸ HakkÄ±nda"])

with tab1:
    st.header("Dosya YÃ¼kleme")
    
   uploaded_file = st.file_uploader(
    "Almanca haber dosyanÄ±zÄ± yÃ¼kleyin (.txt, .docx veya .pdf)",
    type=['txt', 'docx', 'pdf']  # â† pdf ekle
)
    
    if uploaded_file:
    # DosyayÄ± oku
    if uploaded_file.name.endswith('.docx'):
        text = extract_text_from_docx(uploaded_file)
    elif uploaded_file.name.endswith('.pdf'):  # â† EKLE
        text = extract_text_from_pdf(uploaded_file)  # â† EKLE
    else:
        text = uploaded_file.read().decode('utf-8')
        
        text = clean_text(text)
        
        st.success(f"âœ… Dosya yÃ¼klendi: {uploaded_file.name}")
        st.info(f"ğŸ“ Toplam karakter: {len(text)}")
        
        # Ã–nizleme
        with st.expander("ğŸ“„ Metin Ã–nizleme"):
            st.text(text[:1000] + "..." if len(text) > 1000 else text)
        
        # Analiz butonu
        if st.button("ğŸš€ Analizi BaÅŸlat", type="primary"):
            with st.spinner("Analiz yapÄ±lÄ±yor..."):
                
                # CÃ¼mlelere ayÄ±r
                sentences = split_into_sentences(text)
                st.info(f"ğŸ“Š Toplam cÃ¼mle: {len(sentences)}")
                
                # Anahtar kelime eÅŸleÅŸmelerini bul
                matches = find_keyword_contexts(
                    sentences, 
                    keywords,
                    context_before,
                    context_after
                )
                
                if not matches:
                    st.warning("âŒ Anahtar kelime bulunamadÄ±!")
                else:
                    st.success(f"âœ… {len(matches)} eÅŸleÅŸme bulundu!")
                    
                    # Her eÅŸleÅŸme iÃ§in analiz yap
                    progress_bar = st.progress(0)
                    results = []
                    
                    for idx, match in enumerate(matches):
                        # Analiz
                        analysis = analyze_text_with_all_models(match['context'])
                        
                        results.append({
                            **match,
                            **analysis
                        })
                        
                        progress_bar.progress((idx + 1) / len(matches))
                    
                    # SonuÃ§larÄ± session state'e kaydet
                    st.session_state['results'] = results
                    st.session_state['analyzed'] = True
                    
                    st.success("âœ… Analiz tamamlandÄ±! 'SonuÃ§lar' sekmesine gidin.")

with tab2:
    st.header("ğŸ“Š Analiz SonuÃ§larÄ±")
    
    if 'analyzed' in st.session_state and st.session_state['analyzed']:
        results = st.session_state['results']
        
        st.info(f"ğŸ“ˆ Toplam {len(results)} baÄŸlam analiz edildi")
        
        # Her sonucu gÃ¶ster
        for idx, result in enumerate(results):
            with st.expander(f"ğŸ” EÅŸleÅŸme {idx+1}: '{result['keyword']}' - CÃ¼mle {result['sentence_index']}"):
                
                # Context gÃ¶ster
                st.markdown("**ğŸ“ BaÄŸlam:**")
                st.write(result['context'])
                
                st.markdown("---")
                
                # Model sonuÃ§larÄ±
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**Model 1: HÄ±zlÄ± Pilot**")
                    sentiment_1 = result['model_1']['sentiment']
                    st.metric("Sentiment", sentiment_1)
                
                with col2:
                    st.markdown("**Model 2: Haber**")
                    sentiment_2 = result['model_2']['sentiment']
                    st.metric("Sentiment", sentiment_2)
                
                with col3:
                    st.markdown("**Model 3: DetaylÄ±**")
                    top_emotion = result['model_3']['top_emotions'][0]
                    st.metric(
                        "Top Duygu", 
                        top_emotion['label'],
                        f"{top_emotion['score']:.2%}"
                    )
                
                # Model 3 detaylarÄ±
                st.markdown("**ğŸ­ Top 5 Duygu (Model 3):**")
                emotion_df = pd.DataFrame(result['model_3']['top_emotions'])
                st.dataframe(emotion_df, use_container_width=True)
                
                # Radar chart
                fig = create_emotion_radar_chart(result['model_3']['top_emotions'])
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
        
        # Ã–zet tablo
        st.markdown("---")
        st.subheader("ğŸ“‹ Ã–zet Tablo")
        df = create_results_dataframe(results)
        st.dataframe(df, use_container_width=True)
        
        # CSV indirme
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ğŸ“¥ SonuÃ§larÄ± CSV olarak indir",
            data=csv,
            file_name="qatar_sentiment_results.csv",
            mime="text/csv"
        )
        
    else:
        st.info("ğŸ‘ˆ Ã–nce 'Dosya YÃ¼kle' sekmesinden bir dosya yÃ¼kleyin ve analiz baÅŸlatÄ±n.")

with tab3:
    st.header("â„¹ï¸ Proje HakkÄ±nda")
    
    st.markdown("""
    ### ğŸ¯ AmaÃ§
    Qatar DÃ¼nya KupasÄ± ile ilgili Almanca haber metinlerinde duygu analizi yapmak ve 
    farklÄ± modellerin performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak.
    
    ### ğŸ“š KullanÄ±lan Modeller
    
    **1. Model 1: HÄ±zlÄ± Pilot**
    - Oliver Guhr et al. (LREC 2020)
    - 1.8M Almanca Ã¶rnek
    - 3 kategori: positive, negative, neutral
    - F1 Score: ~0.96
    
    **2. Model 2: Haber Metinleri**
    - mdraw/german-news-sentiment-bert
    - Haber dili iÃ§in Ã¶zelleÅŸtirilmiÅŸ
    - 2007-2019 gÃ¶Ã§ haberleri ile eÄŸitilmiÅŸ
    
    **3. Model 3: DetaylÄ± Akademik**
    - GoEmotions (Google, ACL 2020)
    - 27 farklÄ± duygu kategorisi
    - Ã‡ok dilli BERT
    
    ### ğŸ”¬ Metodoloji
    - **Context Window:** Anahtar kelimenin 3 cÃ¼mle Ã¶ncesi ve sonrasÄ±
    - **Ã‡oklu Model:** ÃœÃ§ farklÄ± yaklaÅŸÄ±mÄ±n karÅŸÄ±laÅŸtÄ±rmasÄ±
    - **Akademik Standart:** Peer-reviewed modeller
    
    ### ğŸ“– Kaynaklar
    - [Guhr et al. 2020 - LREC](http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.202.pdf)
    - [GoEmotions - ACL 2020](https://aclanthology.org/2020.acl-main.372/)
    - [GitHub Repository](https://github.com/laikakos/laikaresearch)
    """)

st.markdown("---")
st.markdown("ğŸ’¡ **Ä°pucu:** Sidebar'dan anahtar kelimeleri ve context window ayarlarÄ±nÄ± Ã¶zelleÅŸtirebilirsiniz.")
